{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462054f7-e060-46ce-8838-68e54288c3b4",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e350d-1ead-46de-8087-392a2d384ea3",
   "metadata": {},
   "source": [
    "## Importing the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135a440f-a559-4f48-88cc-52cff8197bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377fc03-4149-46fe-b6cd-21136b701614",
   "metadata": {},
   "source": [
    "## Imputing Values and Encoding Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5fef65-ae88-40f6-9dd4-ee6639f69c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "num_imp = SimpleImputer(strategy='constant', fill_value=0)\n",
    "cat_imp = SimpleImputer(strategy='constant')\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e8728-72ce-4171-b5b1-ce00655df2c5",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1997f36-7e59-48f0-b173-c2b4f03c8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, is_train=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    #cabin split\n",
    "    df[['Deck', 'CabinNum', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "    df['Group'] = df['PassengerId'].str.split('_').str[0]\n",
    "    \n",
    "    # Map booleans\n",
    "    df['CryoSleep'] = df['CryoSleep'].map({'True': 1, 'False': 0})\n",
    "    df['VIP'] = df['VIP'].map({'True': 1, 'False': 0})\n",
    "\n",
    "    if not is_train:\n",
    "        passenger_ids = df['PassengerId']\n",
    "    else:\n",
    "        passenger_ids = None\n",
    "\n",
    "    df.drop(columns=['PassengerId', 'Cabin', 'Name'], inplace=True)\n",
    "\n",
    "    if is_train:\n",
    "        y = df['Transported'].astype(int)\n",
    "        df.drop(columns='Transported', inplace=True)\n",
    "    else:\n",
    "        y = None\n",
    "    # Feature engineering\n",
    "    spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
    "    df['SpentAny'] = (df['TotalSpend'] > 0).astype(int)\n",
    "    df['CryoSpend'] = df['CryoSleep'] * df['SpentAny']\n",
    "\n",
    "    # Numerical columns\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if is_train:\n",
    "        df[num_cols] = num_imp.fit_transform(df[num_cols])\n",
    "    else:\n",
    "        df[num_cols] = num_imp.transform(df[num_cols])\n",
    "\n",
    "    # Categorical columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    if is_train:\n",
    "        df[cat_cols] = cat_imp.fit_transform(df[cat_cols])\n",
    "        df[cat_cols] = encoder.fit_transform(df[cat_cols])\n",
    "    else:\n",
    "        df[cat_cols] = cat_imp.transform(df[cat_cols])\n",
    "        df[cat_cols] = encoder.transform(df[cat_cols])\n",
    "\n",
    "    return df, y, passenger_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7394d-10db-42ca-8dd8-07482d3abf05",
   "metadata": {},
   "source": [
    "## Specifying X and y for model and Splitting the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e721fbe7-b0de-43de-ade7-e82ab4dc0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all, _ = preprocess(train_df, is_train=True)\n",
    "X_test, _, test_ids = preprocess(test_df, is_train=False)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f73fb7-2fe1-48e8-8125-50942541a399",
   "metadata": {},
   "source": [
    "## Class weights and Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca24f32c-be7d-482f-8298-919a2fddf7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "RF Val Accuracy: 0.7918343875790684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "cw_dict = {i: w for i, w in enumerate(cw)}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, class_weight=cw_dict),\n",
    "    param_grid, cv=3, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "print(\"Best RF Params:\", grid.best_params_)\n",
    "print(\"RF Val Accuracy:\", accuracy_score(y_val, best_rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4338dbb-5e03-4967-86c6-8a56603fa92e",
   "metadata": {},
   "source": [
    "## Using XGBoost/XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9527161e-73d5-4ac0-b233-96d4223dfe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranbir Singh\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [17:17:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Val Accuracy: 0.8010350776308223\n",
      " Using model: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                    use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"XGB Val Accuracy:\", accuracy_score(y_val, xgb.predict(X_val)))\n",
    "\n",
    "model = xgb if accuracy_score(y_val, xgb.predict(X_val)) > accuracy_score(y_val, best_rf.predict(X_val)) else best_rf\n",
    "print(\" Using model:\", type(model).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbde09-5bdc-443d-b761-a7568b8d30a6",
   "metadata": {},
   "source": [
    "## Getting Training values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0364fb93-95b9-4aaf-9b55-4e7ebeee10ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Model: XGBClassifier\n",
      " Train Accuracy: 0.8759\n",
      " Validation Accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "final_train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "final_val_acc = accuracy_score(y_val, model.predict(X_val))\n",
    "\n",
    "print(f\" Final Model: {type(model).__name__}\")\n",
    "print(f\" Train Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\" Validation Accuracy: {final_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cab5a2-d98d-4042-a1f3-0420dba579c6",
   "metadata": {},
   "source": [
    "### we can do better than this so we try better case with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0f08fd-9e0f-4513-9048-8a4ac124e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranbir Singh\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [17:17:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Val Accuracy with new features: 0.8010\n"
     ]
    }
   ],
   "source": [
    "xgb_new_features = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                                 use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "xgb_new_features.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val_new_features = xgb_new_features.predict(X_val)\n",
    "\n",
    "accuracy_new_features = accuracy_score(y_val, y_pred_val_new_features)\n",
    "print(f\"XGB Val Accuracy with new features: {accuracy_new_features:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d957d0-79d8-4f53-9f68-72181d649ccc",
   "metadata": {},
   "source": [
    "### no change in accuracy so we shift to new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef45c4dd-ec74-45b0-bb30-a816721bde3b",
   "metadata": {},
   "source": [
    "## Using LightGBM and CatBosst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441bc29d-29a8-41a7-aecb-876b44ce8c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2140\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "LightGBM Val ROC AUC: 0.8930\n",
      "CatBoost Val ROC AUC: 0.8967\n",
      "XGBoost Val ROC AUC: 0.8913\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba_lgbm = lgbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_lgbm = roc_auc_score(y_val, y_pred_proba_lgbm)\n",
    "print(f\"LightGBM Val ROC AUC: {roc_auc_lgbm:.4f}\")\n",
    "\n",
    "catboost = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba_catboost = catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_catboost = roc_auc_score(y_val, y_pred_proba_catboost)\n",
    "print(f\"CatBoost Val ROC AUC: {roc_auc_catboost:.4f}\")\n",
    "\n",
    "y_pred_proba_xgb = xgb_new_features.predict_proba(X_val)[:, 1]\n",
    "roc_auc_xgb = roc_auc_score(y_val, y_pred_proba_xgb)\n",
    "print(f\"XGBoost Val ROC AUC: {roc_auc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48a775-43ff-4b14-8b5c-8f4c4a94fa7d",
   "metadata": {},
   "source": [
    "## Trying new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a6aeea-51c7-419b-8462-0e15805019e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2140\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best LightGBM Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      " Best CatBoost Params: {'depth': 7, 'iterations': 300, 'l2_leaf_reg': 5, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "lgbm_grid_search = GridSearchCV(LGBMClassifier(random_state=42), lgbm_param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "lgbm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LightGBM Params:\", lgbm_grid_search.best_params_)\n",
    "\n",
    "catboost_param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [3, 5, 7],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "catboost_grid_search = GridSearchCV(CatBoostClassifier(random_state=42, verbose=0), catboost_param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "catboost_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\" Best CatBoost Params:\", catboost_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f906dd-e58e-4a51-9639-7f66fb05e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2140\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Tuned LightGBM Val ROC AUC: 0.8907\n",
      "Tuned CatBoost Val ROC AUC: 0.8949\n"
     ]
    }
   ],
   "source": [
    "best_lgbm = LGBMClassifier(**lgbm_grid_search.best_params_, random_state=42)\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba_best_lgbm = best_lgbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_best_lgbm = roc_auc_score(y_val, y_pred_proba_best_lgbm)\n",
    "print(f\"Tuned LightGBM Val ROC AUC: {roc_auc_best_lgbm:.4f}\")\n",
    "\n",
    "best_catboost = CatBoostClassifier(**catboost_grid_search.best_params_, random_state=42, verbose=0)\n",
    "best_catboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba_best_catboost = best_catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_best_catboost = roc_auc_score(y_val, y_pred_proba_best_catboost)\n",
    "print(f\"Tuned CatBoost Val ROC AUC: {roc_auc_best_catboost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6288bfe-d664-4aca-9340-7b395fe540b8",
   "metadata": {},
   "source": [
    "## Out of Both, CATBoost is better so we go with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfd26782-7c26-49d0-a5ba-620c9b4697f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ROC AUC scores: [0.83952589 0.70543183 0.85741837 0.91494653 0.88960901]\n",
      "Mean Cross-validation ROC AUC: 0.8414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "selected_model = best_catboost\n",
    "\n",
    "cv_scores = cross_val_score(selected_model, X_all, y_all, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"Cross-validation ROC AUC scores:\", cv_scores)\n",
    "print(f\"Mean Cross-validation ROC AUC: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c2c2db-11e9-4eae-99b0-c041a1347897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CatBoost Val ROC AUC: 0.8949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba_catboost_final = best_catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_catboost_final = roc_auc_score(y_val, y_pred_proba_catboost_final)\n",
    "\n",
    "print(f\"Final CatBoost Val ROC AUC: {roc_auc_catboost_final:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734b83e-4f31-4b09-8b20-b6816957354e",
   "metadata": {},
   "source": [
    "## Final Testing and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8fa497-a66a-46bd-9fa7-a3daa585e416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 submission_best.csv saved!\n"
     ]
    }
   ],
   "source": [
    "# Use the predict_proba() method of the best_catboost model to predict the probabilities\n",
    "y_pred_proba_test = best_catboost.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create a pandas DataFrame named submission\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_ids,\n",
    "    \"Transported\": (y_pred_proba_test > 0.5).astype(bool)\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv(\"submission_best.csv\", index=False)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"🎉 submission_best.csv saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
